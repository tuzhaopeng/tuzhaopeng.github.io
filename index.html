<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
	
<title>Zhaopeng Tu's Homepage</title>

<style type="text/css">
    body {
        font-family: cambria, calibri, garamond, century, gulim, dotum, arial;
        font-size: 18px;
        margin: 0 auto;
        width: 90%;
        min-width: 200px;
        max-width: 1200px;
        width: expression_r(Math.max(200, Math.min(1200, document.body.offsetWidth-40)) + "px");
    }
</style>

<style>
table {
    font-family: cambria, calibri, garamond, century, gulim, dotum, arial;
    border-collapse: collapse;
    width: 100%;
    font-size:18px;}
</style>

</head>
<body>


<table class="wsite-multicol-table">
<tbody class="wsite-multicol-tbody">
<tr class="wsite-multicol-tr">

<td class="wsite-multicol-col">
    <img src="images/head.jpg" height=204.75 width=307.2 border="0"  align="center">

    <br/>
    <h2>Zhaopeng Tu</h2>

    <p>Principal Researcher<br />
    Hunyuan AI Digital Human, Tencent<br />
    tuzhaopeng@gmail.com</p>
</td>

</tr>
</tbody>
</table>


<h2>Bio</h2>
<p>Zhaopeng Tu is a principal researcher at Tencent, whose research focuses on large language models.
He has published over 100 papers in leading NLP/AI journals and conferences such as ICML, ACL, EMNLP, ICLR, and TACL. 
He served as Associate Editor of NeuroComputing, Area Chair or Senior PC Member of ACL, EMNLP, NAACL, AAAI, and IJCAI.</p>

<!--p></p>
<center><font color="#008F00">Please refer to <a href="intern.html">research intern positions</a> for the information about internship.</font></center-->

<h2>News</h2> 

<p></p>

<ul>
  <li type="circle">2025-05: 2 papers were accepted to ICML2025, and 8 papers were accepted to ACL2025.</li>        
  <li type="circle">2025-01: 3 papers were accepted to ICLR2025.</li>        
  <li type="circle">2024-10: Our paper titled "<i>GPT4Video: A Unified Multimodal Large Language Model for lnstruction-Followed Understanding and Safety-Aware Generation</i>" was <font color="#C4260B"><b>nominated for the Best Paper Award</b></font> at ACM MM 2024.</li>        
  <li type="circle">2024-09: 3 papers (including 2 D&B Papers) were accepted to NeurIPS2024, and 1 paper was accepted to EMNLP2024.</li>        
  <li type="circle">2024-05: 1 paper was accepted to ICML2024, and 6 papers were accepted to ACL2024.</li>    
  <li type="circle">2022-11: Our paper titled "<i>Adapters for Enhanced Modeling of Multilingual Knowledge and Text</i>" was selected as the <font color="#C4260B"><b>Best Paper Award</b></font> at MRL Workshop in EMNLP2022.</li>
</ul>

<p></p>


<h2>Selected Publications</h2> 

<a href="publications.html">full list</a>

<p></p>
<h3>Agents</h3>
<ul>
    <li type="circle">Peisong Wang, Ruotian Ma, Bang Zhang, Xingyu Chen, Zhiwei He, Kang Luo, Qingsong Lv, Qingxuan Jiang, Zheng Xie, Shanyi Wang, Yuan Li, Fanghua Ye, Jian Li, Yifan Yang, <u>Zhaopeng Tu</u>*, and Xiaolong Li. <a href="https://arxiv.org/abs/2507.03112"><font color="#0080FF">RLVER: Reinforcement Learning with Verifiable Emotion Rewards for Empathetic Agents</font></a>. <i>Preprint</i>. <a href="https://x.com/tuzhaopeng/status/1940963412848398449">X</a></li>
    <li type="circle">Bang Zhang, Ruotian Ma, Qingxuan Jiang, Peisong Wang, Jiaqi Chen, Zheng Xie, Xingyu Chen, Yue Wang, Fanghua Ye, Jian Li, Yifan Yang, <u>Zhaopeng Tu</u>*, and Xiaolong Li. <a href="https://arxiv.org/abs/2505.02847"><font color="#0080FF">Sentient Agent as a Judge: Evaluating Higher-Order Social Cognition in Large Language Models</font></a>. <i>Preprint</i>. <a href="https://x.com/tuzhaopeng/status/1917604867058852304">X</a></li>
    <li type="circle">Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Shuming Shi, and <u>Zhaopeng Tu</u>. <a href="https://arxiv.org/abs/2305.19118"><font color="#0080FF">Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate</font></a>. <i>EMNLP 2024</i>.</li>
    <li type="circle">Jen-tse Huang, Man Ho LAM, Eric John Li, Shujie Ren, Wenxuan Wang, Wenxiang Jiao, <u>Zhaopeng Tu</u>, and Michael Lyu. <a href="https://openreview.net/forum?id=pwRVGRWtGg"><font color="#0080FF">Apathetic or Empathetic? Evaluating LLMs' Emotional Alignments with Humans</font></a>. <i>NeurIPS 2024</i>.</li>
    <li type="circle">Jen-tse Huang, Wenxuan Wang, Eric John Li, Man Ho LAM, Shujie Ren, Youliang Yuan, Wenxiang Jiao, <u>Zhaopeng Tu</u>, and Michael Lyu. <a href="https://openreview.net/forum?id=H3UayAQWoE"><font color="#0080FF">On the Humanity of Conversational AI: Evaluating the Psychological Portrayal of LLMs</font></a>. <i>ICLR 2024</i> (Oral, 1.2%).</li>
</ul>


<h3>Long Reasoning Models (LRMs)</h3>
<ul>
    <li type="circle">Xingyu Chen, Jiahao Xu, Tian Liang, Zhiwei He, Jianhui Pang, Dian Yu, Linfeng Song, Qiuzhi Liu, Mengfei Zhou, Zhuosheng Zhang, Rui Wang, <u>Zhaopeng Tu</u>*, Haitao Mi, and Dong Yu. <a href="https://arxiv.org/abs/2412.21187"><font color="#0080FF">Do NOT Think That Much for 2+3=? On the Overthinking of o1-Like LLMs</font></a>. <i>ICML 2025</i>. <a href="https://x.com/tuzhaopeng/status/1873924882012291463">X</a></li>
    <li type="circle">Yue Wang, Qiuzhi Liu, Jiahao Xu, Tian Liang, Xingyu Chen, Zhiwei He, Linfeng Song, Dian Yu, Juntao Li, Zhuosheng Zhang, Rui Wang, <u>Zhaopeng Tu</u>*, Haitao Mi, and Dong Yu. <a href="https://arxiv.org/abs/2501.18585"><font color="#0080FF">Thoughts Are All Over the Place: On the Underthinking of o1-Like LLMs</font></a>. <i>Preprint</i>. <a href="https://x.com/tuzhaopeng/status/1885179412163027406">X</a></li>
    <li type="circle">Zicheng Lin, Tian Liang, Jiahao Xu, Qiuzhi Liu, Xing Wang, Ruilin Luo, Chufan Shi, Siheng Li, Yujiu Yang, and <u>Zhaopeng Tu</u>*. <a href="https://arxiv.org/abs/2411.19943"><font color="#0080FF">Critical Tokens Matter: Token-Level Contrastive Estimation Enhances LLM's Reasoning Capability</font></a>. <i>ICML 2025</i>. <a href="https://x.com/tuzhaopeng/status/1879065390992753149">X</a></li>
    <li type="circle">Ante Wang, Linfeng Song, Ye Tian, Dian Yu, Haitao Mi, Xiangyu Duan, <u>Zhaopeng Tu</u>*, Jinsong Su, and Dong Yu. <a href="https://arxiv.org/abs/2502.11183"><font color="#0080FF">Don't Get Lost in the Trees: Streamlining LLM Reasoning by Overcoming Tree Search Exploration Pitfalls</font></a>. <i>ACL 2025</i>. <a href="https://x.com/tuzhaopeng/status/1891346931433255300">X</a></li>

    <li type="circle">Xiaoyuan Liu, Tian Liang, Zhiwei He, Jiahao Xu, Wenxuan Wang, Pinjia He, <u>Zhaopeng Tu</u>*, Haitao Mi, and Dong Yu. <a href="https://arxiv.org/abs/2505.13445"><font color="#0080FF">Trust, But Verify: A Self-Verification Approach to Reinforcement Learning with Verifiable Rewards</font></a>. <i>Preprint</i>. <a href="https://x.com/tuzhaopeng/status/1924838749676175617">X</a></li>
    <li type="circle">Mengru Wang, Xingyu Chen, Yue Wang, Zhiwei He, Jiahao Xu, Tian Liang, Qiuzhi Liu, Yunzhi Yao, Wenxuan Wang, Ruotian Ma, Haitao Mi, Ningyu Zhang, <u>Zhaopeng Tu</u>*, Xiaolong Li, and Dong Yu. <a href="https://arxiv.org/abs/2505.14681"><font color="#0080FF">Two Experts Are All You Need for Steering Thinking: Reinforcing Cognitive Effort in MoE Reasoning Models Without Additional Training</font></a>. <i>Preprint</i>. <a href="https://x.com/tuzhaopeng/status/1925198471923138891">X</a></li>

    <li type="circle">Ke Ji, Jiahao Xu, Tian Liang, Qiuzhi Liu, Zhiwei He, Xingyu Chen, Xiaoyuan Liu, Zhijie Wang, Junying Chen, Benyou Wang, <u>Zhaopeng Tu</u>*, Haitao Mi, and Dong Yu. <a href="http://dx.doi.org/10.13140/RG.2.2.33772.07043"><font color="#0080FF">The First Few Tokens Are All You Need: An Efficient and Effective Unsupervised Prefix Fine-Tuning Method for Reasoning Models</font></a>. <i>Preprint</i>. <a href="https://x.com/tuzhaopeng/status/1895420224683516413">X</a></li>
    <li type="circle">Yansi Li, Jiahao Xu, Tian Liang, Xingyu Chen, Zhiwei He, Qiuzhi Liu, Rui Wang, Zhuosheng Zhang, <u>Zhaopeng Tu</u>*, Haitao Mi, and Dong Yu. <a href="https://arxiv.org/abs/2503.17363"><font color="#0080FF">Dancing with Critiques: Enhancing LLM Reasoning with Stepwise Natural Language Self-Critique</font></a>. <i>Preprint</i>. <a href="https://x.com/tuzhaopeng/status/1900823893809791007">X</a></li>	
    <li type="circle">Yi Su, Dian Yu, Linfeng Song, Juntao Li, Haitao Mi, Zhaopeng Tu, Min Zhang, and Dong Yu. <a href="https://arxiv.org/abs/2503.23829"><font color="#0080FF">Crossing the Reward Bridge: Expanding RL with Verifiable Rewards Across Diverse Domains</font></a>. <i>Preprint</i>. <a href="https://x.com/tuzhaopeng/status/1906975869538914570">X</a></li>	
    <li type="circle">Zhiwei He, Tian Liang, Jiahao Xu, Qiuzhi Liu, Xingyu Chen, Yue Wang, Linfeng Song, Dian Yu, Zhenwen Liang, Wenxuan Wang, Zhuosheng Zhang, Rui Wang, <u>Zhaopeng Tu</u>*, Haitao Mi, and Dong Yu. <a href="https://arxiv.org/abs/2504.11456"><font color="#0080FF">DeepMath-103K: A Large-Scale, Challenging, Decontaminated, and Verifiable Mathematical Dataset for Advancing Reasoning</font></a>. <i>Preprint</i>. <a href="https://x.com/tuzhaopeng/status/1912057561110782446">X</a></li>	
</ul>


<h3>Multimodal Large Language Models (MLLMs)</h3>
<ul>
    <li type="circle">Wenxuan Wang, Xiaoyuan Liu, Kuiyi Gao, Jen-tse Huang, Youliang Yuan, Pinjia He, Shuai Wang, and <u>Zhaopeng Tu</u>*. <a href="https://arxiv.org/abs/2502.11184"><font color="#0080FF">Can't See the Forest for the Trees: Benchmarking Multimodal Safety Awareness for Multimodal LLMs</font></a>. <i>ACL 2025</i>.
    <li type="circle">Xiaoyuan Liu, Wenxuan Wang, Youliang Yuan, Jen-tse Huang, Qiuzhi Liu, Pinjia He, and <u>Zhaopeng Tu</u>. <a href="https://arxiv.org/abs/2410.08145"><font color="#0080FF">Insight Over Sight: Exploring the Vision-Knowledge Conflicts in Multimodal LLMs</font></a>. <i>ACL 2025</i>.
    <li type="circle">Wenxuan Wang, Kuiyi Gao, Youliang Yuan, Jen-tse Huang, Qiuzhi Liu, Shuai Wang, Wenxiang Jiao, and <u>Zhaopeng Tu</u>*. <a href="https://arxiv.org/abs/2410.03869"><font color="#0080FF">Chain-of-Jailbreak Attack for Image Generation Models via Step by Step Editing</font></a>. <i>ACL 2025 (Findings)</i>.

    <li type="circle">Jen-Tse Huang, Dasen Dai, Jen-Yuan Huang, Youliang Yuan, Xiaoyuan Liu, Wenxuan Wang, Wenxiang Jiao, Pinjia He, and <u>Zhaopeng Tu</u>*. <a href="https://arxiv.org/abs/2502.16435"><font color="#0080FF">VisFactor: Benchmarking Fundamental Visual Cognition in Multimodal Large Language Models</font></a>. <i>Preprint</i>.</li>

    <li type="circle">Mingxiao Li, Na Su, Fang Qu, Zhizhou Zhong, Ziyang Chen, Yuan Li, <u>Zhaopeng Tu</u>*, and Xiaolong Li. <a href="https://arxiv.org/abs/2505.10917"><font color="#0080FF">VISTA: Enhancing Vision-Text Alignment in MLLMs via Cross-Modal Mutual Information Maximization</font></a>. <i>Preprint</i>. <a href="https://x.com/tuzhaopeng/status/1924483497512800372">X</a></li>

    <li type="circle">Zhanyu Wang, Longyue Wang, Zhen Zhao, Minghao Wu, Chenyang Lyu, Huayang Li, Deng Cai, Luping Zhou, Shuming Shi, and <u>Zhaopeng Tu</u>. <a href="https://arxiv.org/abs/2311.16511"><font color="#0080FF">GPT4Video: A Unified Multimodal Large Language Model for lnstruction-Followed Understanding and Safety-Aware Generation</font></a>. <i>ACM MM 2024</i>. [<font color="#C4260B"><b>Best Paper Normination</b></font>]</li>
    <li type="circle">Chenyang Lyu, Minghao Wu, Longyue Wang, Xinting Huang, Bingshuai Liu, Zefeng Du, Shuming Shi, and <u>Zhaopeng Tu</u>. <a href="https://arxiv.org/abs/2306.09093"><font color="#0080FF">Macaw-LLM: Multi-Modal Language Modeling with Image, Audio, Video, and Text Integration</font></a>. <i>Preprint</i>. [<a href="https://github.com/lyuchenyang/Macaw-LLM">Project</a>]</li>
</ul>


<h3>Large Language Models (LLMs)</h3>
<ul>	
    <li type="circle">Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Xing Wang, and <u>Zhaopeng Tu</u>. <a href="https://arxiv.org/abs/2301.08745"><font color="#0080FF">Is ChatGPT A Good Translator? Yes With GPT-4 As The Engine</font></a>. <i>Preprint</i>.</li>

    <li type="circle">Wenxuan Wang, Wenxiang Jiao, Jingyuan Huang, Ruyi Dai, Jen-tse Huang, <u>Zhaopeng Tu</u>*, and Michael R Lyu. <a href="https://arxiv.org/abs/2310.12481"><font color="#0080FF">Not All Countries Celebrate Thanksgiving: On the Cultural Dominance in Large Language Models</font></a>. <i>ACL 2024</i>.</li>

    <li type="circle">Youliang Yuan, Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Jiahao Xu, Tian Liang, Pinjia He, and <u>Zhaopeng Tu</u>. <a href="https://arxiv.org/abs/2407.09121"><font color="#0080FF">Refuse Whenever You Feel Unsafe: Improving Safety in LLMs via Decoupled Refusal Training</font></a>. <i>ACL 2025</i>. <a href="https://x.com/youliang_yuan/status/1812665889852121332">X</a></li>
    <li type="circle">Youliang Yuan, Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Pinjia He, Shuming Shi, and <u>Zhaopeng Tu</u>. <a href="https://arxiv.org/abs/2308.06463"><font color="#0080FF">GPT-4 is too Smart to be Safe: Stealthy Chat with LLMs via Cipher</font></a>. <i>ICLR 2024</i>.</li>
    
    <li type="circle">Zhiwei He, Tian Liang, Wenxiang Jiao, Zhuosheng Zhang, Yujiu Yang, Rui Wang, <u>Zhaopeng Tu</u>*, Shuming Shi, and Xing Wang. <a href="https://arxiv.org/abs/2305.04118"><font color="#0080FF">Exploring Human-Like Translation Strategy with Large Language Models</font></a>. <i>TACL 2024</i>.</li>
    <li type="circle">Zhiwei He, Xing Wang, Wenxiang Jiao, Zhuosheng Zhang, Rui Wang, Shuming Shi, and <u>Zhaopeng Tu</u>. <a href="https://arxiv.org/abs/2401.12873"><font color="#0080FF">Improving Machine Translation with Human Feedback: An Exploration of Quality Estimation as a Reward Model</font></a>. <i>NAACL 2024</i>.</li>
    
    <li type="circle">Longyue Wang, Chenyang Lyu, Tianbo Ji, Zhirui Zhang, Dian Yu, Shuming Shi, and <u>Zhaopeng Tu</u>. <a href="https://arxiv.org/pdf/2304.02210.pdf"><font color="#0080FF">Document-Level Machine Translation with Large Language Models</font></a>. <i>EMNLP 2023</i>.</li>
    <li type="circle">Yifan Hou, Wenxiang Jiao, Meizhen Liu, Carl Allen, <u>Zhaopeng Tu</u>, and Mrinmaya Sachan. <font color="#0080FF">Adapters for Enhanced Modeling of Multilingual Knowledge and Text</font>. <i>EMNLP 2022 (Findings)</i>. [<font color="#C4260B"><b>Best Paper of MRL Workshop</b></font>]</li>
</ul>


<h3>Neural Machine Translation (NMT)</h3>
<ul>
    <li type="circle"><u>Zhaopeng Tu</u>, Yang Liu, Shuming Shi, and Tong Zhang. <a href="https://arxiv.org/abs/1711.09367"><font color="#0080FF">Learning to Remember Translation History with a Continuous Cache</font></a>. <i>TACL 2018</i>. </li>
    <li type="circle"><u>Zhaopeng Tu</u>, Yang Liu, Lifeng Shang, Xiaohua Liu, and Hang Li. <a href="https://arxiv.org/abs/1611.01874"><font color="#0080FF">Neural Machine Translation with Reconstruction</font></a>. <i>AAAI 2017</i>. [<a href="https://github.com/tuzhaopeng/NMT">code</a>]</li>
    <li type="circle"><u>Zhaopeng Tu</u>, Yang Liu, Zhengdong Lu, Xiaohua Liu, and Hang Li. <a href="http://arxiv.org/abs/1608.06043"><font color="#0080FF">Context Gates for Neural Machine Translation</font></a>. <i>TACL 2017</i>. [<a href="https://github.com/tuzhaopeng/NMT">code</a>]</li>
    <li type="circle"><u>Zhaopeng Tu</u>, Zhengdong Lu, Yang Liu, Xiaohua Liu, and Hang Li. <a href="http://arxiv.org/abs/1601.04811"><font color="#0080FF">Modeling Coverage for Neural Machine Translation</font></a>. <i>ACL 2016</i>. [<a href="https://github.com/tuzhaopeng/NMT-Coverage">code</a>]</li>
</ul>
<p></p>





<!--p></p>

<h2>Selected Professional Services</h2>

<p></p>

<h3>Journals</h3>
<ul>
    <li type="circle">NeuroComputing: Associate Editor (2020-)</li>
    <li type="circle">Computational Linguistics: Reviewer (2016-)</li>
</ul>

<h3>Conferences</h3>
<ul>
    <li type="circle">Virtual Infrastracture Chair: EMNLP (2021)</li>
    <li type="circle">Area Chair: ACL (2019,2023), EMNLP (2018-2019), NAACL (2019)</li>
    <li type="circle">Senior Program Committee: AAAI (2019), IJCAI (2021)</li>
</ul-->

</body>
</html>
